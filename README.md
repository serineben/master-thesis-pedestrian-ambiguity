# ğŸš¶ Pedestrian Detection in Autonomous Driving using YOLOv8 & LLaVA

[![Python](https://img.shields.io/badge/Python-3.10-blue?logo=python)](https://www.python.org/)
[![OpenCV](https://img.shields.io/badge/OpenCV-4.8-blue?logo=opencv)](https://opencv.org/)
[![LinkedIn](https://img.shields.io/badge/LinkedIn-Profile-blue?logo=linkedin)](https://www.linkedin.com/in/serine-benmohra-55715b33b)
[![License](https://img.shields.io/badge/License-MIT-green)](LICENSE)

This Master's Thesis project explores advanced pedestrian detection in urban driving scenarios using **YOLOv8** and **LLaVA**. The research focuses on handling challenging cases such as partial visibility, occlusions, and ambiguous pedestrian appearances to enhance autonomous driving safety.

---

## ğŸ“– Abstract

Pedestrian detection remains a critical challenge in autonomous driving systems, particularly in complex urban environments. This thesis investigates the integration of **YOLOv8** for real-time object detection and **LLaVA** (Large Language-and-Vision Assistant) for contextual scene understanding to improve detection accuracy in ambiguous scenarios. The proposed approach demonstrates enhanced performance in identifying partially visible and occluded pedestrians compared to traditional methods.

---

## ğŸ“‚ Repository Structure
```bash
master-thesis-pedestrian-ambiguity/
â”œâ”€â”€ ğŸ“Š data/
â”‚   â””â”€â”€ dataset_person_summary.csv
â”œâ”€â”€ ğŸ”§ src/
â”‚   â”œâ”€â”€ extraireframe.py
â”‚   â”œâ”€â”€ image_selection.py
â”‚   â”œâ”€â”€ run_yolo_detection.py
â”‚   â”œâ”€â”€ real-time-yolo.py
â”‚   â””â”€â”€ LLAVAselectiontheone.py
â”œâ”€â”€ ğŸ“ˆ results/
â”‚   â”œâ”€â”€ pipeline.png
â”‚   â”œâ”€â”€ false_positive1.jpg
â”‚   â”œâ”€â”€ false_positive2.jpg
â”‚   â””â”€â”€ conclusion/
â”‚       â”œâ”€â”€ YOLO_confusion_matrix.png
â”‚       â”œâ”€â”€ LLAVA_confusion_matrix.png
â”‚       â”œâ”€â”€ heatmap_yolo_vs_llava.png
â”‚       â””â”€â”€ summary_metrics.csv
â”œâ”€â”€ ğŸ“„ thesis/
â”‚   â””â”€â”€ master_thesis_document.pdf
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```
> Note: Full datasets and extensive results are not included due to size constraints. Contact me for access to complete research materials.

---
**ğŸ› ï¸ Methodology**

**Pipeline Overview**
<img src="images/pipeline.png" alt="Research Pipeline" width="700"/>

ğŸ¬ Frame Extraction - Extract relevant frames from driving scenario videos

ğŸ‘ï¸ Manual Curation - Select frames containing pedestrians using interactive GUI

ğŸ¤– YOLOv8 Detection - Perform initial pedestrian detection using YOLOv8

ğŸ” LLaVA Analysis - Apply vision-language model for contextual understanding

ğŸ“Š Comparative Evaluation - Analyze results using confusion matrices and heatmaps

---

## ğŸ“Š Key Results

### Detection Performance

The combined YOLOv8 + LLaVA approach shows significant improvement in handling ambiguous cases:

*Reduced false positives* in complex urban scenes

*Enhanced detection* of partially visible pedestrians

*Better contextual* understanding of occluded scenarios

**âŒ False Positive Analysis**
Examples where YOLOv8 alone produces incorrect detections:

<img src="images/yolo_false_positive1.jpg" alt="False Positive Case 1" width="400"/> <img src="images/yolo_false_positive2.jpg" alt="False Positive Case 2" width="400"/>
**ğŸ“ˆ Performance Metrics**
Comparative analysis of YOLOv8 and LLaVA performance:

<img src="results/conclusion/YOLO_confusion_matrix.png" alt="YOLO Confusion Matrix" width="400"/> <img src="results/conclusion/LLAVA_confusion_matrix.png" alt="LLaVA Confusion Matrix" width="400"/> <img src="results/conclusion/heatmap_yolo_vs_llava.png" alt="YOLO vs LLaVA Performance Heatmap" width="400"/>

---
### âš™ï¸ Installation & Usage
**Prerequisites**
```bash
# Clone repository
git clone https://github.com/yourusername/master-thesis-pedestrian-ambiguity.git
cd master-thesis-pedestrian-ambiguity

# Install dependencies
pip install -r requirements.txt 
```

**Execution Pipeline** 
```bash
# Run the complete analysis pipeline
python src/extract_frames.py
python src/image_selection.py
python src/run_yolo_detection.py
python src/llava_analysis.py
python src/analyze_results.py

# For real-time demonstration
python src/real_time_yolo.py
```

**ğŸ‘¨â€ğŸ“ Author**
Serine Benmohra
Master's Student in Computer Science/Artificial Intelligence
[https://img.shields.io/badge/LinkedIn-Connect-blue?logo=linkedin](https://www.linkedin.com/in/serine-benmohra-55715b33b)
This project represents my Master's Thesis research in Universidad de Alicante.

**ğŸ“ Citation**
If you use this work in your research, please cite:
```bash
@mastersthesis{benmohra2025pedestrian,
  title={Pedestrian Detection in Autonomous Driving using YOLOv8 and LLaVA},
  author={Benmohra, Serine},
  year={2025},
  school={Universidad de Alicante}
}
```











