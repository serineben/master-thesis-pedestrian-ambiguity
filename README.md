# ğŸš¶ Pedestrian Detection in Autonomous Driving using YOLOv8 & LLaVA

[![Python](https://img.shields.io/badge/Python-3.10-blue?logo=python)](https://www.python.org/)
[![OpenCV](https://img.shields.io/badge/OpenCV-4.8-blue?logo=opencv)](https://opencv.org/)
[![LinkedIn](https://img.shields.io/badge/LinkedIn-Profile-blue?logo=linkedin)](https://www.linkedin.com/in/serine-benmohra-55715b33b)


This Master's Thesis project explores advanced pedestrian detection in urban driving scenarios using **YOLOv8** and **LLaVA**. The research focuses on handling challenging cases such as partial visibility, occlusions, and ambiguous pedestrian appearances to enhance autonomous driving safety.

---

## ğŸ“– Abstract

Pedestrian detection remains a critical challenge in autonomous driving systems, particularly in complex urban environments. This thesis investigates the integration of **YOLOv8** for real-time object detection and **LLaVA** (Large Language-and-Vision Assistant) for contextual scene understanding to improve detection accuracy in ambiguous scenarios. The proposed approach demonstrates enhanced performance in identifying partially visible and occluded pedestrians compared to traditional methods.

---

## ğŸ“‚ Repository Structure
```bash
master-thesis-pedestrian-ambiguity/
â”œâ”€â”€ ğŸ“Š data/
â”‚   â””â”€â”€ dataset_person_summary.csv
â”œâ”€â”€ ğŸ”§ src/
â”‚   â”œâ”€â”€ analyze_results.py
â”‚   â”œâ”€â”€ image_selection.py
â”‚   â”œâ”€â”€ run_yolo_detection.py
â”‚   â”œâ”€â”€ real_time_yolo.py
â”‚   â””â”€â”€ extract_frames.py
â”‚   â””â”€â”€ llava_analysis.py
â”œâ”€â”€ ğŸ“ˆ results/
â”‚   â”œâ”€â”€ llava-results.csv
â”‚   â”œâ”€â”€ merged-results.csv
â”‚   â”œâ”€â”€ yolo-results.csv
â”‚   â””â”€â”€ conclusion/
â”‚       â”œâ”€â”€ YOLO_confusion_matrix.png
â”‚       â”œâ”€â”€ LLAVA_confusion_matrix.png
â”‚       â”œâ”€â”€ heatmap_yolo_vs_llava.png
â”‚       â””â”€â”€ summary_metrics.csv
â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ pipeline.png
â”‚   â”œâ”€â”€ yolo_false_positive1.jpg
â”‚   â”œâ”€â”€ yolo_false_positive2.jpg
â”œâ”€â”€ ğŸ“„ thesis/
â”‚   â””â”€â”€ master_thesis_document.pdf
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```
> Note: Full datasets and extensive results are not included due to size constraints. Contact me for access to complete research materials.

---
**ğŸ› ï¸ Methodology**

**Pipeline Overview**
<img src="images/pipeline.png" alt="Research Pipeline" width="400" height="400"/>

ğŸ¬ Frame Extraction - Extract relevant frames from driving scenario videos

ğŸ‘ï¸ Manual Curation - Select frames containing pedestrians using interactive GUI

ğŸ¤– YOLOv8 Detection - Perform initial pedestrian detection using YOLOv8

ğŸ” LLaVA Analysis - Apply vision-language model for contextual understanding

ğŸ“Š Comparative Evaluation - Analyze results using confusion matrices and heatmaps

---

## ğŸ“Š Key Results

### Detection Performance

The combined YOLOv8 + LLaVA approach shows significant improvement in handling ambiguous cases:

**Reduced false positives** in complex urban scenes

**Enhanced detection** of partially visible pedestrians

**Better contextual** understanding of occluded scenarios

**âŒ False Positive Analysis**
Examples where YOLOv8 alone produces incorrect detections:

<img src="images/yolo_false_positive1.jpg" alt="False Positive Case 1" width="400"/> <img src="images/yolo_false_positive2.jpg" alt="False Positive Case 2" width="400"/>


**ğŸ“ˆ Performance Metrics**
Comparative analysis of YOLOv8 and LLaVA performance:

<img src="results/conclusion/YOLO_confusion_matrix.png" alt="YOLO Confusion Matrix" width="400"/> <img src="results/conclusion/LLAVA_confusion_matrix.png" alt="LLaVA Confusion Matrix" width="400"/> 

---
### âš™ï¸ Installation & Usage
**Prerequisites**
```bash
# Clone repository
git clone https://github.com/serineben/master-thesis-pedestrian-ambiguity.git
cd master-thesis-pedestrian-ambiguity

# Install dependencies
pip install -r requirements.txt 
```

**Execution Pipeline** 
```bash
# Run the complete analysis pipeline
python src/extract_frames.py
python src/image_selection.py
python src/run_yolo_detection.py
python src/llava_analysis.py
python src/analyze_results.py

# For real-time demonstration
python src/real_time_yolo.py
```


## ğŸ‘¨â€ğŸ“ Author

**Serine Benmohra**  
ğŸ“§ serinebenmohra@gmail.com  
ğŸ”— [LinkedIn Profile](https://www.linkedin.com/in/serine-benmohra-55715b33b)  
ğŸ“ Master's Student in Artificial Intelligence  
ğŸ« Universidad de Alicante  

*This Master's Thesis research focuses on pedestrian detection systems for autonomous vehicles.*

**ğŸ“ Citation**
If you use this work in your research, please cite:
```bash
@mastersthesis{benmohra2025pedestrian,
  title={Pedestrian Detection in Autonomous Driving using YOLOv8 and LLaVA},
  author={Benmohra, Serine},
  year={2025},
  school={Universidad de Alicante}
}
```














